bamboo-7b:
  draft_model: /root/models/lite-mistral-150m.gguf
  model: /root/models/bamboo-7b-orig.gguf

default:
  cffn: 0
  ctx_size: 768
  max_tokens: 512
  n_prompts: 10
  ngl: 999
  no_mmap: 0
  prompt_file: prompts.txt
  spif:
    dfr_ema: ''
    dx_dfr_decay: ''
    init_dfr_decay: ''
    parallel: ''
    reload: ''
    reload_window_size: ''
    reorder: ''
    split_debug: ''
  threads: 12

opt-13b:
  draft_model: /root/models/opt-125m.gguf
  model: /root/models/opt-13b-orig.gguf

opt-30b:
  draft_model: /root/models/opt-125m.gguf
  model: /root/models/opt-30b-orig-q8_0.gguf

opt-6.7b:
  draft_model: /root/models/opt-125m.gguf
  model: /root/models/opt-6.7b-orig.gguf

prosparse-llama-2-13b:
  draft_model: /root/models/llama-160m-chat.gguf
  model: /root/models/prosparse-llama-2-13b-orig.gguf

prosparse-llama-2-7b:
  draft_model: /root/models/llama-160m-chat.gguf
  model: /root/models/prosparse-llama-2-7b-orig.gguf

relufalcon-40b:
  model: /root/models/relufalcon-40b-orig-q8_0.gguf

sparseqwen2-7b:
  draft_model: /root/models/qwen2-0.5b-instruct-q8_0.gguf
  model: /root/models/sparseqwen2-7b-orig.gguf
